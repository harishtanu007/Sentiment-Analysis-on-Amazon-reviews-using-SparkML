{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pyspark.ml import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.param import *\n",
    "from pyspark.ml.tuning import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import rand \n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc =SparkContext()\n",
    "print (sc.version)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So there is no way for me to plug it in here in the US unless I go by a converter.\\t0',\n",
       " 'Good case, Excellent value.\\t1',\n",
       " 'Great for the jawbone.\\t1',\n",
       " 'Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\\t0',\n",
       " 'The mic is great.\\t1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.textFile(\"amazon_cells_labelled.txt\")\n",
    "rdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['So there is no way for me to plug it in here in the US unless I go by a converter.',\n",
       "  '0'],\n",
       " ['Good case, Excellent value.', '1'],\n",
       " ['Great for the jawbone.', '1'],\n",
       " ['Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!',\n",
       "  '0'],\n",
       " ['The mic is great.', '1']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split a review sentence and a corresponding label \n",
    "rdd2 = rdd1.map(lambda x: x.split(\"\\t\"))\n",
    "rdd2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review='So there is no way for me to plug it in here in the US unless I go by a converter.', label='0'),\n",
       " Row(review='Good case, Excellent value.', label='1'),\n",
       " Row(review='Great for the jawbone.', label='1'),\n",
       " Row(review='Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!', label='0'),\n",
       " Row(review='The mic is great.', label='1')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RDD of Rows with the field names : label and review\n",
    "rdd3 = rdd2.map(lambda x: Row(review=x[0],label=x[1]))\n",
    "rdd3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              review|label|\n",
      "+--------------------+-----+\n",
      "|So there is no wa...|  0.0|\n",
      "|Good case, Excell...|  1.0|\n",
      "|Great for the jaw...|  1.0|\n",
      "|Tied to charger f...|  0.0|\n",
      "|   The mic is great.|  1.0|\n",
      "|I have to jiggle ...|  0.0|\n",
      "|If you have sever...|  0.0|\n",
      "|If you are Razr o...|  1.0|\n",
      "|Needless to say, ...|  0.0|\n",
      "|What a waste of m...|  0.0|\n",
      "|And the sound qua...|  1.0|\n",
      "|He was very impre...|  1.0|\n",
      "|If the two were s...|  0.0|\n",
      "|Very good quality...|  1.0|\n",
      "|The design is ver...|  0.0|\n",
      "|Highly recommend ...|  1.0|\n",
      "|I advise EVERYONE...|  0.0|\n",
      "|    So Far So Good!.|  1.0|\n",
      "|       Works great!.|  1.0|\n",
      "|It clicks into pl...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "# Converting an RDD to DataFrame\n",
    "df=sqlContext.createDataFrame(rdd3)\n",
    "# Registers this DataFrame as a temporary table using the given name\n",
    "df.registerTempTable(\"df\")\n",
    "# convert String labels to Double type\n",
    "df = df.withColumn(\"label\", df.label.cast(DoubleType()))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(features=SparseVector(262144, {51471: 4.8293, 109156: 5.8101, 113100: 4.4238, 148675: 4.9628, 235273: 5.5225, 254682: 6.2156}), label=0.0)\n",
      "Row(features=SparseVector(262144, {78745: 3.5766, 113432: 2.5913, 123499: 5.117, 192310: 3.5076}), label=1.0)\n",
      "Row(features=SparseVector(262144, {135499: 5.5225, 261870: 2.3238}), label=1.0)\n"
     ]
    }
   ],
   "source": [
    "# convert the distinct labels in the input dataset to index values\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(df)\n",
    "# tokenizer \n",
    "tokenizer = RegexTokenizer(inputCol=\"review\", outputCol=\"words\", pattern=\"\\W\")##'\\w' remove none-word letters\n",
    "df_tokenized = tokenizer.transform(df)\n",
    "# remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "df_removed = remover.transform(df_tokenized)\n",
    "# Convert to TF words vector\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n",
    "df_TF = hashingTF.transform(df_removed)\n",
    "# Convert to TF*IDF words vector\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(df_TF)\n",
    "df_idf = idfModel.transform(df_TF)\n",
    "for features_label in df_idf.select(\"features\", \"label\").take(3):\n",
    "    print(features_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number in the train set : 808\n",
      "Sample number in the test set : 192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  count\n",
       "0    0.0    422\n",
       "1    1.0    386"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data aproximately into training (80%) and test (20%)\n",
    "(train, test)=df.randomSplit([0.8,0.2], seed = 0)\n",
    "# Cache the train and test data in-memory \n",
    "train = train.cache()\n",
    "test = test.cache()\n",
    "print ('Sample number in the train set : {}'.format(train.count()))\n",
    "print ('Sample number in the test set : {}'.format(test.count()))\n",
    "train.groupby('label').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(p1,p2,p3,p4):\n",
    "    lr = LogisticRegression()\n",
    "    pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, lr])\n",
    "  \n",
    "    #Create ParamGrid for Cross Validation\n",
    "    paramGrid = (ParamGridBuilder()\n",
    "                 .addGrid(hashingTF.numFeatures, [p1])\n",
    "                 .addGrid(lr.regParam, [p2])\n",
    "                 .addGrid(lr.elasticNetParam, [p3])\n",
    "                 .addGrid(lr.maxIter, [p4])\n",
    "                 .build())\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=evaluator,\n",
    "                              numFolds=4)\n",
    "    \n",
    "    ########  Run cross-validation, and choose the best set of parameters.\n",
    "    cvModel = crossval.fit(train)\n",
    "    # average cross-validation accuracy metric/s on all folds\n",
    "    average_score = cvModel.avgMetrics\n",
    "    print ('average cross-validation accuracy = {}'.format(average_score[0]))\n",
    "    return average_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.09,9)\n",
      "average cross-validation accuracy = 0.8083603645874418\n",
      "Classifier trained in 11.988 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.09,10)\n",
      "average cross-validation accuracy = 0.8110226363927155\n",
      "Classifier trained in 8.387 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.09,11)\n",
      "average cross-validation accuracy = 0.8060339779528034\n",
      "Classifier trained in 8.172 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.1,9)\n",
      "average cross-validation accuracy = 0.809247344073933\n",
      "Classifier trained in 8.399 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.1,10)\n",
      "average cross-validation accuracy = 0.8118715853453029\n",
      "Classifier trained in 7.478 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.1,11)\n",
      "average cross-validation accuracy = 0.810898042635197\n",
      "Classifier trained in 8.778 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.11,9)\n",
      "average cross-validation accuracy = 0.8065037601229479\n",
      "Classifier trained in 7.23 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.11,10)\n",
      "average cross-validation accuracy = 0.8053622076115323\n",
      "Classifier trained in 7.554 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.09,0.11,11)\n",
      "average cross-validation accuracy = 0.8052782699268695\n",
      "Classifier trained in 7.3 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.09,9)\n",
      "average cross-validation accuracy = 0.8086529681462701\n",
      "Classifier trained in 7.005 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.09,10)\n",
      "average cross-validation accuracy = 0.8098404278084443\n",
      "Classifier trained in 6.795 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.09,11)\n",
      "average cross-validation accuracy = 0.8084877183158958\n",
      "Classifier trained in 7.475 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.1,9)\n",
      "average cross-validation accuracy = 0.8067989892207277\n",
      "Classifier trained in 6.78 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.1,10)\n",
      "average cross-validation accuracy = 0.8067989892207277\n",
      "Classifier trained in 8.448 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.1,11)\n",
      "average cross-validation accuracy = 0.8052782699268695\n",
      "Classifier trained in 9.107 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.11,9)\n",
      "average cross-validation accuracy = 0.8076453126343635\n",
      "Classifier trained in 6.73 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.11,10)\n",
      "average cross-validation accuracy = 0.8037142690212038\n",
      "Classifier trained in 7.086 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.1,0.11,11)\n",
      "average cross-validation accuracy = 0.8062491870980237\n",
      "Classifier trained in 7.276 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.09,9)\n",
      "average cross-validation accuracy = 0.8068829269053907\n",
      "Classifier trained in 7.06 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.09,10)\n",
      "average cross-validation accuracy = 0.8067989892207277\n",
      "Classifier trained in 8.028 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.09,11)\n",
      "average cross-validation accuracy = 0.8067989892207277\n",
      "Classifier trained in 7.872 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.1,9)\n",
      "average cross-validation accuracy = 0.8049830408290897\n",
      "Classifier trained in 7.234 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.1,10)\n",
      "average cross-validation accuracy = 0.8049830408290897\n",
      "Classifier trained in 7.839 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.1,11)\n",
      "average cross-validation accuracy = 0.8075179589059094\n",
      "Classifier trained in 6.978 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.11,9)\n",
      "average cross-validation accuracy = 0.8073068019247762\n",
      "Classifier trained in 7.541 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.11,10)\n",
      "average cross-validation accuracy = 0.8085322921208546\n",
      "Classifier trained in 7.148 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(45000,0.11,0.11,11)\n",
      "average cross-validation accuracy = 0.8049804152901379\n",
      "Classifier trained in 8.02 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.09,9)\n",
      "average cross-validation accuracy = 0.8149103983940679\n",
      "Classifier trained in 7.387 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.09,10)\n",
      "average cross-validation accuracy = 0.814742523024742\n",
      "Classifier trained in 9.015 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.09,11)\n",
      "average cross-validation accuracy = 0.8147858046365493\n",
      "Classifier trained in 7.944 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.1,9)\n",
      "average cross-validation accuracy = 0.8134330951440008\n",
      "Classifier trained in 8.463 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.1,10)\n",
      "average cross-validation accuracy = 0.8182943998554588\n",
      "Classifier trained in 7.551 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.1,11)\n",
      "average cross-validation accuracy = 0.816814336634456\n",
      "Classifier trained in 8.944 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.11,9)\n",
      "average cross-validation accuracy = 0.814447293926962\n",
      "Classifier trained in 7.283 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.11,10)\n",
      "average cross-validation accuracy = 0.8118256781945439\n",
      "Classifier trained in 11.448 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.09,0.11,11)\n",
      "average cross-validation accuracy = 0.8107247817559841\n",
      "Classifier trained in 10.979 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.09,9)\n",
      "average cross-validation accuracy = 0.8174021692910644\n",
      "Classifier trained in 9.727 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.09,10)\n",
      "average cross-validation accuracy = 0.8184624096567685\n",
      "Classifier trained in 11.44 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.09,11)\n",
      "average cross-validation accuracy = 0.814531231611625\n",
      "Classifier trained in 9.917 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.1,9)\n",
      "average cross-validation accuracy = 0.8132218037308836\n",
      "Classifier trained in 10.205 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.1,10)\n",
      "average cross-validation accuracy = 0.8132624598037392\n",
      "Classifier trained in 10.606 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.1,11)\n",
      "average cross-validation accuracy = 0.8109360731691011\n",
      "Classifier trained in 8.783 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.11,9)\n",
      "average cross-validation accuracy = 0.8094153538752428\n",
      "Classifier trained in 8.73 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.11,10)\n",
      "average cross-validation accuracy = 0.8059067586563334\n",
      "Classifier trained in 7.79 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.1,0.11,11)\n",
      "average cross-validation accuracy = 0.8080625099507103\n",
      "Classifier trained in 8.983 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.09,9)\n",
      "average cross-validation accuracy = 0.8093340417295314\n",
      "Classifier trained in 8.784 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.09,10)\n",
      "average cross-validation accuracy = 0.814447293926962\n",
      "Classifier trained in 8.573 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.09,11)\n",
      "average cross-validation accuracy = 0.8111473645822181\n",
      "Classifier trained in 10.259 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.1,9)\n",
      "average cross-validation accuracy = 0.8106001879984654\n",
      "Classifier trained in 8.435 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.1,10)\n",
      "average cross-validation accuracy = 0.8082738013638272\n",
      "Classifier trained in 8.964 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.1,11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cross-validation accuracy = 0.8092447185349815\n",
      "Classifier trained in 8.223 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.11,9)\n",
      "average cross-validation accuracy = 0.808908833364346\n",
      "Classifier trained in 8.068 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.11,10)\n",
      "average cross-validation accuracy = 0.8056954672432163\n",
      "Classifier trained in 7.68 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(50000,0.11,0.11,11)\n",
      "average cross-validation accuracy = 0.8016370699016028\n",
      "Classifier trained in 8.728 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.09,9)\n",
      "average cross-validation accuracy = 0.8183783375401217\n",
      "Classifier trained in 7.533 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.09,10)\n",
      "average cross-validation accuracy = 0.822393453269928\n",
      "Classifier trained in 8.447 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.09,11)\n",
      "average cross-validation accuracy = 0.8161386485610818\n",
      "Classifier trained in 8.802 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.1,9)\n",
      "average cross-validation accuracy = 0.8144040123151548\n",
      "Classifier trained in 8.371 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.1,10)\n",
      "average cross-validation accuracy = 0.8196498693189428\n",
      "Classifier trained in 8.347 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.1,11)\n",
      "average cross-validation accuracy = 0.8219736304146295\n",
      "Classifier trained in 8.912 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.11,9)\n",
      "average cross-validation accuracy = 0.8126339710742756\n",
      "Classifier trained in 8.25 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.11,10)\n",
      "average cross-validation accuracy = 0.8102236467549744\n",
      "Classifier trained in 9.938 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.09,0.11,11)\n",
      "average cross-validation accuracy = 0.8108547610233897\n",
      "Classifier trained in 11.361 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.09,9)\n",
      "average cross-validation accuracy = 0.8172775755335457\n",
      "Classifier trained in 8.684 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.09,10)\n",
      "average cross-validation accuracy = 0.8167736805616004\n",
      "Classifier trained in 10.283 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.09,11)\n",
      "average cross-validation accuracy = 0.8160547108764189\n",
      "Classifier trained in 9.027 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.1,9)\n",
      "average cross-validation accuracy = 0.8128452624873925\n",
      "Classifier trained in 8.032 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.1,10)\n",
      "average cross-validation accuracy = 0.8128859185602482\n",
      "Classifier trained in 9.052 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.1,11)\n",
      "average cross-validation accuracy = 0.8104349381680913\n",
      "Classifier trained in 8.455 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.11,9)\n",
      "average cross-validation accuracy = 0.8061652494133607\n",
      "Classifier trained in 8.371 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.11,10)\n",
      "average cross-validation accuracy = 0.8048124054888283\n",
      "Classifier trained in 7.973 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.1,0.11,11)\n",
      "average cross-validation accuracy = 0.8072227298081295\n",
      "Classifier trained in 9.185 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.09,9)\n",
      "average cross-validation accuracy = 0.8168169621734076\n",
      "Classifier trained in 8.306 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.09,10)\n",
      "average cross-validation accuracy = 0.8116197722913141\n",
      "Classifier trained in 9.813 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.09,11)\n",
      "average cross-validation accuracy = 0.8116604283641697\n",
      "Classifier trained in 13.063 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.1,9)\n",
      "average cross-validation accuracy = 0.8073094274637278\n",
      "Classifier trained in 9.23 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.1,10)\n",
      "average cross-validation accuracy = 0.8047284678041653\n",
      "Classifier trained in 11.982 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.1,11)\n",
      "average cross-validation accuracy = 0.8071387921234665\n",
      "Classifier trained in 10.264 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.11,9)\n",
      "average cross-validation accuracy = 0.8034596959962796\n",
      "Classifier trained in 10.854 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.11,10)\n",
      "average cross-validation accuracy = 0.8047284678041653\n",
      "Classifier trained in 9.964 seconds\n",
      "(numFeatures,regParam,elasticNetParam,maxIter)=(55000,0.11,0.11,11)\n",
      "average cross-validation accuracy = 0.8023614250966714\n",
      "Classifier trained in 9.758 seconds\n",
      "Best score is 0.822393453269928 at params =(55000, 0.09, 0.09, 10)\n"
     ]
    }
   ],
   "source": [
    "score=0.0\n",
    "for p1 in [45000,50000,55000]:\n",
    "    for p2 in [0.09,0.10,0.11]:\n",
    "        for p3 in [0.09,0.10,0.11]:\n",
    "            for p4 in [9,10,11]:\n",
    "                t0 = time()\n",
    "                print ('(numFeatures,regParam,elasticNetParam,maxIter)=({},{},{},{})'.format(p1,p2,p3,p4))\n",
    "                average_score=grid_search(p1,p2,p3,p4)\n",
    "                tt = time() - t0\n",
    "                print (\"Classifier trained in {} seconds\".format(round(tt,3)))\n",
    "                if average_score > score:\n",
    "                    print ('################ Best score ######################')\n",
    "                    params=(p1,p2,p3,p4)\n",
    "                    score=average_score\n",
    "print ('Best score is {} at params ={}'.format(score, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_modeling(train, test, pipeline, paramGrid):\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=evaluator,\n",
    "                              numFolds=4)\n",
    "    \n",
    "    ########  Run cross-validation, and choose the best set of parameters.\n",
    "    cvModel = crossval.fit(train)\n",
    "    \n",
    "    ########  Make predictions on on the test data\n",
    "    prediction = cvModel.transform(test)\n",
    "    average_score = cvModel.avgMetrics\n",
    "    print ('average cross-validation accuracy = {}'.format(average_score[0]))\n",
    "    ######## Calculate accuracy of the prediction of the test data\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy_score=evaluator.evaluate(prediction)\n",
    "    # another way to calculate accuracy \n",
    "    #correct=prediction.filter(prediction['label']== prediction['prediction']).select(\"label\",\"prediction\")\n",
    "    #accuracy_score = correct.count() / float(test.count())  \n",
    "    print ('Accuracy in the test data = {}'.format(accuracy_score))\n",
    "    \n",
    "    ######## calculate F1 score of the prediction of the test data\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    f1_score=evaluator.evaluate(prediction)\n",
    "    print ('F1 score in the test data = {}'.format(f1_score))\n",
    "    # Calculate area under ROC for the prediction of the test data\n",
    "    #evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "    #ROC_score=evaluator.evaluate(prediction)\n",
    "    #print 'areaUnderROC in the test data = {}'.format(ROC_score)\n",
    "    \n",
    "    ######## Print classification_report\n",
    "    prediction_and_labels=prediction.select(\"label\",\"prediction\")\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for x in prediction_and_labels.collect():\n",
    "        xx = list(x)\n",
    "        try:\n",
    "            tt = int(xx[1])\n",
    "            pp = int(xx[0])\n",
    "            y_true.append(tt)\n",
    "            y_pred.append(pp)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    target_names = ['neg 0', 'pos 1']\n",
    "    print (classification_report(y_true, y_pred, target_names=target_names))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cross-validation accuracy = 0.8132624598037392\n",
      "Accuracy in the test data = 0.8020833333333334\n",
      "F1 score in the test data = 0.8036541005291005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       neg 0       0.83      0.72      0.77        90\n",
      "       pos 1       0.78      0.87      0.82       102\n",
      "\n",
      "    accuracy                           0.80       192\n",
      "   macro avg       0.81      0.80      0.80       192\n",
      "weighted avg       0.81      0.80      0.80       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trained by a logistic regression \n",
    "lr = LogisticRegression()\n",
    "# Build a pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, lr])\n",
    "\n",
    "# Create ParamGrid for Cross Validation \n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(hashingTF.numFeatures, [50000])\n",
    "             .addGrid(lr.regParam, [0.10])\n",
    "             .addGrid(lr.elasticNetParam, [0.10])\n",
    "             .addGrid(lr.maxIter, [10])\n",
    "             .build())\n",
    "# Execute 4-folds cross validation for hyperparameter tuning, model prediction and model evaluation.\n",
    "Data_modeling(train, test, pipeline, paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(p1,p2):\n",
    "    nb = NaiveBayes()\n",
    "    pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, nb])\n",
    "  \n",
    "    #Create ParamGrid for Cross Validation\n",
    "    paramGrid = (ParamGridBuilder()\n",
    "                 .addGrid(hashingTF.numFeatures, [p1])\n",
    "                 .addGrid(nb.smoothing, [p2])\n",
    "                 .build())\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=evaluator,\n",
    "                              numFolds=4)\n",
    "    \n",
    "    ########  Run cross-validation, and choose the best set of parameters.\n",
    "    cvModel = crossval.fit(train)\n",
    "    # average cross-validation accuracy metric/s on all folds\n",
    "    average_score = cvModel.avgMetrics\n",
    "    print ('average cross-validation accuracy = {}'.format(average_score[0]))\n",
    "    return average_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(numFeatures,smoothing)=(35000,0.8)\n",
      "average cross-validation accuracy = 0.7643022187708135\n",
      "Classifier trained in 6.12 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,smoothing)=(35000,0.9)\n",
      "average cross-validation accuracy = 0.7657390003800091\n",
      "Classifier trained in 6.421 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,smoothing)=(35000,1.0)\n",
      "average cross-validation accuracy = 0.7669238345032318\n",
      "Classifier trained in 8.432 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,smoothing)=(40000,0.8)\n",
      "average cross-validation accuracy = 0.768061469282544\n",
      "Classifier trained in 5.296 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,smoothing)=(40000,0.9)\n",
      "average cross-validation accuracy = 0.768061469282544\n",
      "Classifier trained in 6.321 seconds\n",
      "(numFeatures,smoothing)=(40000,1.0)\n",
      "average cross-validation accuracy = 0.7692463034057668\n",
      "Classifier trained in 5.331 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,smoothing)=(55000,0.8)\n",
      "average cross-validation accuracy = 0.7685286259137369\n",
      "Classifier trained in 5.505 seconds\n",
      "(numFeatures,smoothing)=(55000,0.9)\n",
      "average cross-validation accuracy = 0.7697134600369596\n",
      "Classifier trained in 5.524 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,smoothing)=(55000,1.0)\n",
      "average cross-validation accuracy = 0.770938950233038\n",
      "Classifier trained in 5.243 seconds\n",
      "################ Best score ######################\n",
      "Best score is 0.770938950233038 at params =(55000, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score=0.0\n",
    "for p1 in [35000,40000,55000]:\n",
    "    for p2 in [0.8,0.9,1.0]:\n",
    "      t0 = time()\n",
    "      print ('(numFeatures,smoothing)=({},{})'.format(p1,p2))\n",
    "      average_score=grid_search(p1,p2)\n",
    "      tt = time() - t0\n",
    "      print (\"Classifier trained in {} seconds\".format(round(tt,3)))\n",
    "      if average_score > score:\n",
    "        print ('################ Best score ######################')\n",
    "        params=(p1,p2)\n",
    "        score=average_score\n",
    "print ('Best score is {} at params ={}'.format(score, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cross-validation accuracy = 0.7692463034057668\n",
      "Accuracy in the test data = 0.7864583333333334\n",
      "F1 score in the test data = 0.7866680462414771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       neg 0       0.74      0.73      0.74        79\n",
      "       pos 1       0.82      0.82      0.82       113\n",
      "\n",
      "    accuracy                           0.79       192\n",
      "   macro avg       0.78      0.78      0.78       192\n",
      "weighted avg       0.79      0.79      0.79       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trained by a NaÃ¯ve Bayes \n",
    "nb = NaiveBayes()\n",
    "# Build a pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, nb])\n",
    "# Create ParamGrid for Cross Validation \n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(hashingTF.numFeatures, [40000])\n",
    "             .addGrid(nb.smoothing, [1.0])\n",
    "             .build())\n",
    "# Execute 4-folds cross validation for hyperparameter tuning, model prediction and model evaluation.\n",
    "Data_modeling(train, test, pipeline, paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(p1,p2,p3):\n",
    "    # trained by a Decision Tree \n",
    "    dt = DecisionTreeClassifier(labelCol=\"indexedLabel\",impurity=\"entropy\")\n",
    "    pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, dt])\n",
    "  \n",
    "    #Create ParamGrid for Cross Validation\n",
    "    paramGrid = (ParamGridBuilder()\n",
    "                 .addGrid(hashingTF.numFeatures, [p1])\n",
    "                 .addGrid(dt.maxDepth, [p2])\n",
    "                 .addGrid(dt.minInstancesPerNode, [p3])\n",
    "                 .build())\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=evaluator,\n",
    "                              numFolds=4)\n",
    "    \n",
    "    ########  Run cross-validation, and choose the best set of parameters.\n",
    "    cvModel = crossval.fit(train)\n",
    "    # average cross-validation accuracy metric/s on all folds\n",
    "    average_score = cvModel.avgMetrics\n",
    "    print ('average cross-validation accuracy = {}'.format(average_score[0]))\n",
    "    return average_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,23,3)\n",
      "average cross-validation accuracy = 0.7576208723509821\n",
      "Classifier trained in 33.473 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,23,4)\n",
      "average cross-validation accuracy = 0.7592728631053977\n",
      "Classifier trained in 33.976 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,23,5)\n",
      "average cross-validation accuracy = 0.7492523990457503\n",
      "Classifier trained in 35.004 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,24,3)\n",
      "average cross-validation accuracy = 0.759987915058476\n",
      "Classifier trained in 37.162 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,24,4)\n",
      "average cross-validation accuracy = 0.7580473729093192\n",
      "Classifier trained in 35.279 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,24,5)\n",
      "average cross-validation accuracy = 0.7492523990457503\n",
      "Classifier trained in 36.691 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,25,3)\n",
      "average cross-validation accuracy = 0.7634558542045299\n",
      "Classifier trained in 41.212 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,25,4)\n",
      "average cross-validation accuracy = 0.7563586438141512\n",
      "Classifier trained in 37.497 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,25,5)\n",
      "average cross-validation accuracy = 0.7492523990457503\n",
      "Classifier trained in 36.1 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,26,3)\n",
      "average cross-validation accuracy = 0.7634558542045299\n",
      "Classifier trained in 38.366 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,26,4)\n",
      "average cross-validation accuracy = 0.7563586438141512\n",
      "Classifier trained in 46.289 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,26,5)\n",
      "average cross-validation accuracy = 0.7456978966760819\n",
      "Classifier trained in 39.668 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,27,3)\n",
      "average cross-validation accuracy = 0.7634558542045299\n",
      "Classifier trained in 42.823 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,27,4)\n",
      "average cross-validation accuracy = 0.7610979803070421\n",
      "Classifier trained in 39.775 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(65000,27,5)\n",
      "average cross-validation accuracy = 0.7480675649225275\n",
      "Classifier trained in 39.376 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,23,3)\n",
      "average cross-validation accuracy = 0.7573256432532022\n",
      "Classifier trained in 38.878 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,23,4)\n",
      "average cross-validation accuracy = 0.7621464263237885\n",
      "Classifier trained in 38.463 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,23,5)\n",
      "average cross-validation accuracy = 0.746842074726449\n",
      "Classifier trained in 40.745 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,24,3)\n",
      "average cross-validation accuracy = 0.7597359675725034\n",
      "Classifier trained in 35.774 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,24,4)\n",
      "average cross-validation accuracy = 0.7585512678812646\n",
      "Classifier trained in 34.834 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,24,5)\n",
      "average cross-validation accuracy = 0.746842074726449\n",
      "Classifier trained in 33.472 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,25,3)\n",
      "average cross-validation accuracy = 0.7597359675725034\n",
      "Classifier trained in 42.461 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,25,4)\n",
      "average cross-validation accuracy = 0.7585512678812646\n",
      "Classifier trained in 35.587 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,25,5)\n",
      "average cross-validation accuracy = 0.746842074726449\n",
      "Classifier trained in 34.919 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,26,3)\n",
      "average cross-validation accuracy = 0.7597359675725034\n",
      "Classifier trained in 37.607 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,26,4)\n",
      "average cross-validation accuracy = 0.755126610347018\n",
      "Classifier trained in 37.967 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,26,5)\n",
      "average cross-validation accuracy = 0.7432875723567808\n",
      "Classifier trained in 37.321 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,27,3)\n",
      "average cross-validation accuracy = 0.76316062510675\n",
      "Classifier trained in 39.976 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,27,4)\n",
      "average cross-validation accuracy = 0.755126610347018\n",
      "Classifier trained in 35.996 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(70000,27,5)\n",
      "average cross-validation accuracy = 0.7456572406032262\n",
      "Classifier trained in 35.17 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,23,3)\n",
      "average cross-validation accuracy = 0.7597818747232622\n",
      "Classifier trained in 39.647 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,23,4)\n",
      "average cross-validation accuracy = 0.7530993705422628\n",
      "Classifier trained in 38.127 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,23,5)\n",
      "average cross-validation accuracy = 0.7530588489013911\n",
      "Classifier trained in 38.335 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,24,3)\n",
      "average cross-validation accuracy = 0.7610073649193406\n",
      "Classifier trained in 40.506 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,24,4)\n",
      "average cross-validation accuracy = 0.7530993705422628\n",
      "Classifier trained in 37.996 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,24,5)\n",
      "average cross-validation accuracy = 0.7530588489013911\n",
      "Classifier trained in 40.673 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,25,3)\n",
      "average cross-validation accuracy = 0.7621921990425633\n",
      "Classifier trained in 39.811 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,25,4)\n",
      "average cross-validation accuracy = 0.7530993705422628\n",
      "Classifier trained in 38.855 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,25,5)\n",
      "average cross-validation accuracy = 0.7530588489013911\n",
      "Classifier trained in 40.012 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,26,3)\n",
      "average cross-validation accuracy = 0.7621515429697077\n",
      "Classifier trained in 42.803 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,26,4)\n",
      "average cross-validation accuracy = 0.7530993705422628\n",
      "Classifier trained in 40.927 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,26,5)\n",
      "average cross-validation accuracy = 0.7530588489013911\n",
      "Classifier trained in 40.291 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,27,3)\n",
      "average cross-validation accuracy = 0.7633363770929305\n",
      "Classifier trained in 42.543 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,27,4)\n",
      "average cross-validation accuracy = 0.7496747130080162\n",
      "Classifier trained in 41.219 seconds\n",
      "(numFeatures,maxDepth,minInstancesPerNode)=(75000,27,5)\n",
      "average cross-validation accuracy = 0.7506891806549456\n",
      "Classifier trained in 45.932 seconds\n",
      "Best score is 0.7634558542045299 at params =(65000, 25, 3)\n"
     ]
    }
   ],
   "source": [
    "score=0.0\n",
    "for p1 in [65000,70000,75000]:\n",
    "    for p2 in [23,24,25,26,27]:\n",
    "        for p3 in [3,4,5]:\n",
    "          t0 = time()\n",
    "          print ('(numFeatures,maxDepth,minInstancesPerNode)=({},{},{})'.format(p1,p2,p3))\n",
    "          average_score=grid_search(p1,p2,p3)\n",
    "          tt = time() - t0\n",
    "          print (\"Classifier trained in {} seconds\".format(round(tt,3)))\n",
    "          if average_score > score:\n",
    "            print ('################ Best score ######################')\n",
    "            params=(p1,p2,p3)\n",
    "            score=average_score\n",
    "print ('Best score is {} at params ={}'.format(score, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cross-validation accuracy = 0.7585512678812646\n",
      "Accuracy in the test data = 0.765625\n",
      "F1 score in the test data = 0.7673791606564515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       neg 0       0.87      0.66      0.75       103\n",
      "       pos 1       0.69      0.89      0.78        89\n",
      "\n",
      "    accuracy                           0.77       192\n",
      "   macro avg       0.78      0.77      0.76       192\n",
      "weighted avg       0.79      0.77      0.76       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trained by a Decision Tree \n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\",impurity=\"entropy\")\n",
    "# Build a pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, dt])\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(hashingTF.numFeatures, [70000])\n",
    "             .addGrid(dt.maxDepth, [25])\n",
    "             .addGrid(dt.minInstancesPerNode, [4])\n",
    "             .build())\n",
    "# Execute 4-folds cross validation for hyperparameter tuning, model prediction and model evaluation.\n",
    "Data_modeling(train, test, pipeline, paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(p1,p2,p3,p4):\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\",impurity=\"entropy\", seed=5043)\n",
    "    pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, rf])\n",
    "  \n",
    "    #Create ParamGrid for Cross Validation\n",
    "    paramGrid = (ParamGridBuilder()\n",
    "                 .addGrid(hashingTF.numFeatures, [p1])\n",
    "                 .addGrid(rf.numTrees, [p2])\n",
    "                 .addGrid(rf.maxDepth, [p3])\n",
    "                 .addGrid(rf.minInstancesPerNode, [p4])\n",
    "                 .build())\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=evaluator,\n",
    "                              numFolds=4)\n",
    "    \n",
    "    ########  Run cross-validation, and choose the best set of parameters.\n",
    "    cvModel = crossval.fit(train)\n",
    "    # average cross-validation accuracy metric/s on all folds\n",
    "    average_score = cvModel.avgMetrics\n",
    "    print ('average cross-validation accuracy = {}'.format(average_score[0]))\n",
    "    return average_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,30,28,1)\n",
      "average cross-validation accuracy = 0.7229619584481601\n",
      "Classifier trained in 31.121 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,30,28,2)\n",
      "average cross-validation accuracy = 0.6804820578404749\n",
      "Classifier trained in 26.322 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,30,29,1)\n",
      "average cross-validation accuracy = 0.7317990150097206\n",
      "Classifier trained in 33.84 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,30,29,2)\n",
      "average cross-validation accuracy = 0.6793405053290594\n",
      "Classifier trained in 35.251 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,30,30,1)\n",
      "average cross-validation accuracy = 0.738308392743491\n",
      "Classifier trained in 38.76 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,30,30,2)\n",
      "average cross-validation accuracy = 0.6793405053290594\n",
      "Classifier trained in 31.322 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,31,28,1)\n",
      "average cross-validation accuracy = 0.7240479686021316\n",
      "Classifier trained in 32.828 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,31,28,2)\n",
      "average cross-validation accuracy = 0.6690665327263197\n",
      "Classifier trained in 29.185 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,31,29,1)\n",
      "average cross-validation accuracy = 0.721762372472333\n",
      "Classifier trained in 33.41 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,31,29,2)\n",
      "average cross-validation accuracy = 0.670503314335515\n",
      "Classifier trained in 29.604 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,31,30,1)\n",
      "average cross-validation accuracy = 0.7301781795534593\n",
      "Classifier trained in 39.806 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,31,30,2)\n",
      "average cross-validation accuracy = 0.670503314335515\n",
      "Classifier trained in 34.207 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,32,28,1)\n",
      "average cross-validation accuracy = 0.7210580202077719\n",
      "Classifier trained in 34.656 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,32,28,2)\n",
      "average cross-validation accuracy = 0.6941335297861988\n",
      "Classifier trained in 28.499 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,32,29,1)\n",
      "average cross-validation accuracy = 0.7196186130596249\n",
      "Classifier trained in 33.963 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,32,29,2)\n",
      "average cross-validation accuracy = 0.6953590199822772\n",
      "Classifier trained in 31.564 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,32,30,1)\n",
      "average cross-validation accuracy = 0.7206762278863775\n",
      "Classifier trained in 37.306 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(45000,32,30,2)\n",
      "average cross-validation accuracy = 0.6953590199822772\n",
      "Classifier trained in 32.184 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,30,28,1)\n",
      "average cross-validation accuracy = 0.7300087650750929\n",
      "Classifier trained in 34.697 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,30,28,2)\n",
      "average cross-validation accuracy = 0.6835219353710721\n",
      "Classifier trained in 29.121 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,30,29,1)\n",
      "average cross-validation accuracy = 0.7364342051242004\n",
      "Classifier trained in 33.936 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,30,29,2)\n",
      "average cross-validation accuracy = 0.6811522671246266\n",
      "Classifier trained in 34.767 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,30,30,1)\n",
      "average cross-validation accuracy = 0.7363935490513447\n",
      "Classifier trained in 39.529 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,30,30,2)\n",
      "average cross-validation accuracy = 0.6811522671246266\n",
      "Classifier trained in 32.82 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,31,28,1)\n",
      "average cross-validation accuracy = 0.6888860705726433\n",
      "Classifier trained in 39.145 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,31,28,2)\n",
      "average cross-validation accuracy = 0.649240854904893\n",
      "Classifier trained in 41.503 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,31,29,1)\n",
      "average cross-validation accuracy = 0.6921833743784358\n",
      "Classifier trained in 43.343 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,31,29,2)\n",
      "average cross-validation accuracy = 0.649240854904893\n",
      "Classifier trained in 32.713 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,31,30,1)\n",
      "average cross-validation accuracy = 0.689732393986279\n",
      "Classifier trained in 39.366 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,31,30,2)\n",
      "average cross-validation accuracy = 0.6503824074163086\n",
      "Classifier trained in 31.467 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,32,28,1)\n",
      "average cross-validation accuracy = 0.7300614843608744\n",
      "Classifier trained in 39.18 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,32,28,2)\n",
      "average cross-validation accuracy = 0.6886841235541648\n",
      "Classifier trained in 37.125 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,32,29,1)\n",
      "average cross-validation accuracy = 0.7352153926311608\n",
      "Classifier trained in 40.868 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,32,29,2)\n",
      "average cross-validation accuracy = 0.6886841235541648\n",
      "Classifier trained in 35.438 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,32,30,1)\n",
      "average cross-validation accuracy = 0.7404125825132543\n",
      "Classifier trained in 38.516 seconds\n",
      "################ Best score ######################\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(50000,32,30,2)\n",
      "average cross-validation accuracy = 0.6886841235541648\n",
      "Classifier trained in 29.515 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,30,28,1)\n",
      "average cross-validation accuracy = 0.6990394083026159\n",
      "Classifier trained in 34.847 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,30,28,2)\n",
      "average cross-validation accuracy = 0.5859990921396598\n",
      "Classifier trained in 28.782 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,30,29,1)\n",
      "average cross-validation accuracy = 0.6957026061851355\n",
      "Classifier trained in 35.095 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,30,29,2)\n",
      "average cross-validation accuracy = 0.5848142580164372\n",
      "Classifier trained in 29.551 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,30,30,1)\n",
      "average cross-validation accuracy = 0.7014497326219171\n",
      "Classifier trained in 35.223 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,30,30,2)\n",
      "average cross-validation accuracy = 0.5848142580164372\n",
      "Classifier trained in 26.985 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,31,28,1)\n",
      "average cross-validation accuracy = 0.713872954400627\n",
      "Classifier trained in 33.895 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,31,28,2)\n",
      "average cross-validation accuracy = 0.5918853666538533\n",
      "Classifier trained in 27.383 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,31,29,1)\n",
      "average cross-validation accuracy = 0.7085051291782722\n",
      "Classifier trained in 34.934 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,31,29,2)\n",
      "average cross-validation accuracy = 0.5918853666538533\n",
      "Classifier trained in 28.888 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,31,30,1)\n",
      "average cross-validation accuracy = 0.7121410781256359\n",
      "Classifier trained in 43.271 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,31,30,2)\n",
      "average cross-validation accuracy = 0.5918853666538533\n",
      "Classifier trained in 32.609 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,32,28,1)\n",
      "average cross-validation accuracy = 0.719335178310803\n",
      "Classifier trained in 34.765 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,32,28,2)\n",
      "average cross-validation accuracy = 0.6138686668433926\n",
      "Classifier trained in 31.04 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,32,29,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cross-validation accuracy = 0.728886129064274\n",
      "Classifier trained in 35.993 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,32,29,2)\n",
      "average cross-validation accuracy = 0.6138686668433926\n",
      "Classifier trained in 30.442 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,32,30,1)\n",
      "average cross-validation accuracy = 0.7299843999638822\n",
      "Classifier trained in 38.937 seconds\n",
      "(numFeatures,numTrees,maxDepth,minInstancesPerNode)=(55000,32,30,2)\n",
      "average cross-validation accuracy = 0.6138686668433926\n",
      "Classifier trained in 33.872 seconds\n",
      "Best score is 0.7404125825132543 at params =(50000, 32, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "score=0.0\n",
    "for p1 in [45000,50000,55000]:\n",
    "    for p2 in [30,31,32]:\n",
    "        for p3 in [28,29,30]:\n",
    "            for p4 in [1,2]:\n",
    "                t0 = time()\n",
    "                print ('(numFeatures,numTrees,maxDepth,minInstancesPerNode)=({},{},{},{})'.format(p1,p2,p3,p4))\n",
    "                average_score=grid_search(p1,p2,p3,p4)\n",
    "                tt = time() - t0\n",
    "                print (\"Classifier trained in {} seconds\".format(round(tt,3)))\n",
    "                if average_score > score:\n",
    "                  print ('################ Best score ######################')\n",
    "                  params=(p1,p2,p3,p4)\n",
    "                  score=average_score\n",
    "print ('Best score is {} at params ={}'.format(score, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cross-validation accuracy = 0.6921833743784358\n",
      "Accuracy in the test data = 0.7552083333333334\n",
      "F1 score in the test data = 0.7562382936561796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       neg 0       0.90      0.64      0.75       109\n",
      "       pos 1       0.66      0.90      0.76        83\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.78      0.77      0.76       192\n",
      "weighted avg       0.79      0.76      0.75       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\",impurity=\"entropy\", seed=5043)\n",
    "# Build a pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, rf])\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(hashingTF.numFeatures, [50000])\n",
    "             .addGrid(rf.numTrees, [31])\n",
    "             .addGrid(rf.maxDepth, [29])\n",
    "             .addGrid(rf.minInstancesPerNode, [1])\n",
    "             .build())\n",
    "# Execute 4-folds cross validation for hyperparameter tuning, model prediction and model evaluation.\n",
    "Data_modeling(train, test, pipeline, paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(p1,p2,p3,p4):\n",
    "    gbt = GBTClassifier(labelCol=\"indexedLabel\")\n",
    "    pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, gbt])\n",
    "  \n",
    "    #Create ParamGrid for Cross Validation\n",
    "    paramGrid = (ParamGridBuilder()\n",
    "                 .addGrid(hashingTF.numFeatures, [p1])\n",
    "                 .addGrid(gbt.maxIter, [p2]) #(default: 20)\n",
    "                 .addGrid(gbt.maxDepth, [p3])\n",
    "                 .addGrid(gbt.minInstancesPerNode, [p4])\n",
    "                 .build())\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=evaluator,\n",
    "                              numFolds=4)\n",
    "    \n",
    "    ########  Run cross-validation, and choose the best set of parameters.\n",
    "    cvModel = crossval.fit(train)\n",
    "    # average cross-validation accuracy metric/s on all folds\n",
    "    average_score = cvModel.avgMetrics\n",
    "    print ('average cross-validation accuracy = {}'.format(average_score[0]))\n",
    "    return average_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(numFeatures,maxIter,maxDepth,minInstancesPerNode)=(60000,25,18,2)\n"
     ]
    }
   ],
   "source": [
    "score=0.0\n",
    "for p1 in [60000]:\n",
    "    for p2 in [25,26,27]:\n",
    "        for p3 in [18,19,20]:\n",
    "            for p4 in [2]:\n",
    "                t0 = time()\n",
    "                print ('(numFeatures,maxIter,maxDepth,minInstancesPerNode)=({},{},{},{})'.format(p1,p2,p3,p4))\n",
    "                average_score=grid_search(p1,p2,p3,p4)\n",
    "                tt = time() - t0\n",
    "                print (\"Classifier trained in {} seconds\".format(round(tt,3)))\n",
    "                if average_score > score:\n",
    "                  print ('################ Best score ######################')\n",
    "                  params=(p1,p2,p3,p4)\n",
    "                  score=average_score\n",
    "print ('Best score is {} at params ={}'.format(score, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained by a Gradient Boosted Tree \n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\")\n",
    "# Build a pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer,tokenizer, remover, hashingTF, idfModel, gbt])\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(hashingTF.numFeatures, [60000])\n",
    "             .addGrid(gbt.maxIter, [25]) #(default: 20)\n",
    "             .addGrid(gbt.maxDepth, [19])\n",
    "             .addGrid(gbt.minInstancesPerNode, [2])\n",
    "             .build())\n",
    "# Execute 4-folds cross validation for hyperparameter tuning, model prediction and model evaluation.\n",
    "Data_modeling(train, test, pipeline, paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
